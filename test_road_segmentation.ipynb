{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_road_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LstuVtSSRDEGQD7OFyBbCGT8NT30WtfE",
      "authorship_tag": "ABX9TyOroZu/4YAS38k3Ad+XjjR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sskunkworks/ai-notebook/blob/main/test_road_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlTEZbKz7vkf",
        "outputId": "e3c45b7f-f9be-4985-f0cf-cd69d8518595"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git\n",
        "!pip install -U tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/examples.git\n",
            "  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-xk9e328l\n",
            "  Running command git clone -q https://github.com/tensorflow/examples.git /tmp/pip-req-build-xk9e328l\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-examples===fa33ab053877a0acbee1b78c5e3120554b94e5a5-) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-examples===fa33ab053877a0acbee1b78c5e3120554b94e5a5-) (1.15.0)\n",
            "Building wheels for collected packages: tensorflow-examples\n",
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-examples: filename=tensorflow_examples-fa33ab053877a0acbee1b78c5e3120554b94e5a5_-cp37-none-any.whl size=265841 sha256=3f51f2b302a3b958618aa71c06addfae4afb99d37f1092eed482a92323e49bb6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i8x14k6m/wheels/83/64/b3/4cfa02dc6f9d16bf7257892c6a7ec602cd7e0ff6ec4d7d714d\n",
            "Successfully built tensorflow-examples\n",
            "Installing collected packages: tensorflow-examples\n",
            "Successfully installed tensorflow-examples-fa33ab053877a0acbee1b78c5e3120554b94e5a5-\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/e6/0a0eb1c0bb23faabfb7d61968ae1bec8ed31d001239a2b2c786883c5dbbf/tfds_nightly-4.3.0.dev202106240107-py3-none-any.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (21.2.0)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.3.4)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (5.1.4)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->tfds-nightly) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly) (1.53.0)\n",
            "Installing collected packages: tfds-nightly\n",
            "Successfully installed tfds-nightly-4.3.0.dev202106240107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRl1d1Oa60f6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y9UjueD608m"
      },
      "source": [
        "#from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import PIL\n",
        "import sys\n",
        "import os\n",
        "from copy import deepcopy\n",
        "from glob import glob\n",
        "from unittest import mock\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import os.path\n",
        "import scipy.misc\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "from glob import glob\n",
        "from glob import glob1\n",
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PcVLzFN9qyi"
      },
      "source": [
        "def test_for_kitti_dataset(data_dir):\n",
        "    kitti_dataset_path    = os.path.join(data_dir, 'data_road')\n",
        "    training_labels_count = len(glob(os.path.join(kitti_dataset_path, 'training/gt_image_2/*_road_*.png')))\n",
        "    training_images_count = len(glob(os.path.join(kitti_dataset_path, 'training/image_2/*.png')))\n",
        "    testing_images_count  = len(glob(os.path.join(kitti_dataset_path, 'testing/image_2/*.png')))\n",
        "\n",
        "    assert not (training_images_count == training_labels_count == testing_images_count == 0),\\\n",
        "        'Kitti dataset not found. Extract Kitti dataset in {}'.format(kitti_dataset_path)\n",
        "    assert training_images_count == 289, 'Expected 289 training images, found {} images.'.format(training_images_count)\n",
        "    assert training_labels_count == 289, 'Expected 289 training labels, found {} labels.'.format(training_labels_count)\n",
        "    assert testing_images_count == 290, 'Expected 290 testing images, found {} images.'.format(testing_images_count)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ABf25zNAcGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5c2fd3ff-ba4a-418c-d378-9dc2d28645da"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# def gen_batch_function(data_folder, image_shape):\n",
        "#     \"\"\"\n",
        "#     Generate function to create batches of training data\n",
        "#     :param data_folder: Path to folder that contains all the datasets\n",
        "#     :param image_shape: Tuple - Shape of image\n",
        "#     :return:\n",
        "#     \"\"\"\n",
        "def get_batches_fn(data_folder, image_shape, batch_size):\n",
        "  \"\"\"\n",
        "  Create batches of training data\n",
        "  :param batch_size: Batch Size\n",
        "  :return: Batches of training data\n",
        "  \"\"\"\n",
        "  image_paths = glob(os.path.join(data_folder, 'image_2', '*.png'))\n",
        "  label_paths = {\n",
        "      re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
        "      for path in glob(os.path.join(data_folder, 'gt_image_2', '*_road_*.png'))}\n",
        "  \n",
        "  background_color = np.array([255, 0, 255]) # Red color\n",
        "\n",
        "  # image를 셔플링한다.\n",
        "  random.shuffle(image_paths)\n",
        "  # 셔플된 이미지에서 batch 크기만큼씩 index를 증가시킨다.\n",
        "  for batch_i in range(0, len(image_paths), batch_size):\n",
        "      images = []\n",
        "      gt_images = []\n",
        "      # 셔플된 이미지들에서 파일을 읽어오면서 처리한다.\n",
        "      for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
        "          # 라벨 이름을 가져온다.\n",
        "          gt_image_file = label_paths[os.path.basename(image_file)]\n",
        "\n",
        "          # image, gt image를 가져와서 리사이징한다.\n",
        "          image = cv2.resize(np.array(cv2.imread(image_file)),image_shape)\n",
        "          gt_image = cv2.resize(np.array(cv2.imread(gt_image_file)), image_shape)\n",
        "          \n",
        "          # 설정 컬러와 동일한 데이터만 라벨링하고 그 외에는 백그라운드로 처리한다.\n",
        "          # Red channel 사용하여 비교한다.\n",
        "          gt_bg = np.all(gt_image == background_color, axis=2)\n",
        "          return gt_bg\n",
        "          break\n",
        "          gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
        "          print('hi6')\n",
        "          print(gt_bg.shape, np.invert(gt_bg).shape)\n",
        "          gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
        "          print('hi7')\n",
        "          images.append(image)\n",
        "          gt_images.append(gt_image)\n",
        "      break\n",
        "      #yield np.array(images), np.array(gt_images)\n",
        "#return get_batches_fn\n",
        "\n",
        "gt_image = get_batches_fn(os.path.join(data_dir, 'data_road/training'), image_shape, batch_size)\n",
        "img = gt_image.astype(np.uint8)\n",
        "img *= 255\n",
        "print(img)\n",
        "cv2_imshow(img)\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " ...\n",
            " [  0 255 255 ...   0   0   0]\n",
            " [  0 255 255 ...   0   0   0]\n",
            " [255 255 255 ...   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAACgCAAAAADBKoxBAAAC7UlEQVR4nO3bvXLbQAyFUSiT939lp5Bn/BNbEsldEsCeU6VIwYv5TMmFIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB2uF39AJW8ffzT3d79vfoBqnh7/l+WJKAXiOd3XsUPPU1n+fstf4DfvfLecT4X+NGLH1qu5wTfbfm+43hu8NW2b8tuF47wydbftZwuwq/xEeHX9CMEpJ5D1g5IPIctG5B2xljzm+CYeta83TfrvYG8eoZaKiDtjLdOQOqZYo3P8UnxrHG8x9q/gbx45uodkHqm6xqQdE7S8mP8tHpaXm+bdic499XT7nybdbrAJR9bnQ64R5v9l33paXPBfVrMv/Ybc4sT7lZ9fYbftqrf8JDS4zPUExHFr3hM2elp4omIwmc8rOLyXO3cVbzjEOWGZ6wnIgpecoxas9PWE1HtlKOUWZ26nbsytxypxugC9URUOeZYBTYXqSeixDVHyz25UDvvct9zgsSD69UTkfqgUyTdWzOeiEh70VkSzi0cz13Cm86TbWz5eiLyHXWmTFtbxBMRua46WZapfeK5y3LX6TIM7RZPROQ47Bku39mynogElz3HpTPbxnO3REKXjWwez90CCV3zl6lL1LOG039GFmun/Tvo3IGL1RMR7RM6cd6K9UR0L+icdau2c9e6oBPGrV1PRLROaO407bzrW9DEZer5rGtCs3ap57umBU2YpZ2f9Sxo9Cr1PNAxoaGb1PNEw4JGTdLOa9olNGSQel7XraDje9SzTbOCDs3Rzi6tEto/Rj27dSpo5xb1HNKooO1TtDNCm4Q2DlHPKF0K2rBDPEM1KejFGeKZoEVCr4xQzywNEnr2Zz3i4aFHPwPima/8O+i3AeI5S/GEfnx89ZypdkH/Pb14Tle6oC8PL56LFE7o49HVc6G6Bd0itJNB1YRu8kmiaEF/rn4A3hX9Ob5VffCOKr6EvIESqfizLKBMChZ0K/jMrVX7GPsHKDNTcCHlGNkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=576x160 at 0x7F825E10B050>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGh_hP3r_FmI"
      },
      "source": [
        "num_classes = 2\n",
        "image_shape = (576, 160)\n",
        "data_dir = 'drive/MyDrive/datasets/'\n",
        "#runs_dir = './runs'\n",
        "test_for_kitti_dataset(data_dir)\n",
        "#get_batches_fn = gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
        "\n",
        "#test_for_kitti_dataset('drive/MyDrive/datasets/')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Q_DomZ5hBWkq",
        "outputId": "9c3ef9d1-82d8-47cd-eb0f-fc7a14201982"
      },
      "source": [
        "data_folder = os.path.join(data_dir, 'data_road/training')\n",
        "batch_size = 30\n",
        "for i in get_batches_fn(os.path.join(data_dir, 'data_road/training'), image_shape, batch_size):\n",
        "  print(i)\n",
        "# for image, label in get_batches_fn(data_folder, batch_size, image_shape):\n",
        "#   print(image, label)  \n",
        "# image_file = 'drive/MyDrive/datasets/data_road/training/image_2/umm_000048.png'\n",
        "# img = Image.open(image_file)\n",
        "# print(img.getdata())\n",
        "# img_arr = np.array(img.getdata())\n",
        "# print(np.resize(img_arr,image_shape).shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[255   0   0 ... 255   0   0]\n",
            " [255   0   0 ... 255   0   0]\n",
            " [255   0   0 ... 255   0   0]\n",
            " ...\n",
            " [255   0   0 ... 255   0   0]\n",
            " [255   0   0 ... 255   0   0]\n",
            " [255   0   0 ... 255   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b51ba16d1637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_road/training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batches_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_road/training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for image, label in get_batches_fn(data_folder, batch_size, image_shape):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ENKLB876wco"
      },
      "source": [
        "OUTPUT_CHANNELS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nn7ujeu6KLS",
        "outputId": "ebb4753e-8b27-4ad1-c256-476b519d6cc5"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "\n",
        "#이 층들의 활성화를 이용합시다\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# 특징추출 모델을 만듭시다\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCMoH7tc6-D9"
      },
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD3bFOFZ6-dO"
      },
      "source": [
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # 모델을 통해 다운샘플링합시다\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # 건너뛰기 연결을 업샘플링하고 설정하세요\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # 이 모델의 마지막 층입니다\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6DQ-0Jj7ATI"
      },
      "source": [
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLDLS8wm7B9s"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elYHK_3f7GUi"
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\n에포크 이후 예측 예시 {}\\n'.format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn1Uchl27Gni"
      },
      "source": [
        "EPOCHS = 20\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}