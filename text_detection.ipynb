{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1H5wRStu2WDB8L0amBefADGXCnUk0wpv-",
      "authorship_tag": "ABX9TyO75TynTCHXF/q7Lqds3vnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sskunkworks/ai-notebook/blob/main/text_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnEfUs8WyueN"
      },
      "source": [
        "import os, h5py, numpy as np\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, InputLayer\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, Concatenate\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, merge\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg5Oj9CUFxFr"
      },
      "source": [
        "class text_binary_crossentropy:\n",
        "    def __getattr__(self, name):\n",
        "        if name == '__name__':\n",
        "            return 'text_binary_crossentropy'\n",
        "        raise AttributeError\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        return K.mean(K.binary_crossentropy(y_pred, y_true), axis=1)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf35Y0P_004R"
      },
      "source": [
        "vgg16_weights_path = 'drive/MyDrive/weights/vgg16_weights.h5'\n",
        "\n",
        "def pretrained_vgg16():\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(input_shape=(224,224,3)))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero1_1'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, name='conv1_1'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero1_2'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, name='conv1_2'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max1_1'))\n",
        "\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero2_1'))\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, name='conv2_1'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero2_2'))\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, name='conv2_2'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max2_1'))\n",
        "\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero3_1'))\n",
        "  model.add(Conv2D(filters=256, kernel_size=3, name='conv3_1'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero3_2'))\n",
        "  model.add(Conv2D(filters=256, kernel_size=3, name='conv3_2'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero3_3'))\n",
        "  model.add(Conv2D(filters=256, kernel_size=3, name='conv3_3'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max3_1'))\n",
        "\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero4_1'))\n",
        "  model.add(Conv2D(filters=512, kernel_size=3, name='conv4_1'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero4_2'))\n",
        "  model.add(Conv2D(filters=512, kernel_size=3, name='conv4_2'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero4_3'))\n",
        "  model.add(Conv2D(filters=512, kernel_size=3, name='conv4_3'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max4_1'))\n",
        "\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero5_1'))\n",
        "  model.add(Conv2D(filters=512, kernel_size=3, name='conv5_1'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero5_2'))\n",
        "  model.add(Conv2D(filters=512, kernel_size=3, name='conv5_2'))\n",
        "  model.add(ZeroPadding2D(padding=(1, 1), name='zero5_3'))\n",
        "  model.add(Conv2D(filters=512, kernel_size=3, name='conv5_3'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='max5_1'))\n",
        "\n",
        "  # model.summary()\n",
        "    \n",
        "  f = h5py.File(vgg16_weights_path)\n",
        "  for k in range(f.attrs['nb_layers']):\n",
        "    if k >= len(model.layers):\n",
        "      break\n",
        "      g = f['layer_{}'.format(k)]\n",
        "      weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
        "      model.layers[k].set_weights(weights)\n",
        "      model.layers[k].trainable = False\n",
        "  f.close()\n",
        "  \n",
        "  conv_dict = dict([(layer.name, layer)\n",
        "      for layer in model.layers if isinstance(layer, Convolution2D)])\n",
        "  return model, conv_dict\n",
        "\n",
        "pre_model = pretrained_vgg16()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5XRchBDdy82"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def my_vgg16():\n",
        "  input = Input(shape =(224,224,3))\n",
        "  # 1st Conv Block\n",
        "  x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu', name='conv1_1')(input)\n",
        "  x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu', name='conv1_2')(x)\n",
        "  x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  # 2nd Conv Block\n",
        "  x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu', name='conv2_1')(x)\n",
        "  x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu', name='conv2_2')(x)\n",
        "  x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  # 3rd Conv block  \n",
        "  x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu', name='conv3_1')(x) \n",
        "  x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu', name='conv3_2')(x) \n",
        "  x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu', name='conv3_3')(x) \n",
        "  x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  # 4th Conv block\n",
        "  x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu', name='conv4_1')(x)\n",
        "  x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu', name='conv4_2')(x)\n",
        "  x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu', name='conv4_3')(x)\n",
        "  x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  # 5th Conv block\n",
        "  x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu', name='conv5_1')(x)\n",
        "  x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu', name='conv5_2')(x)\n",
        "  x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu', name='conv5_3')(x)\n",
        "  x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "  \n",
        "  return Model(inputs=input, outputs =x)\n",
        "\n",
        "base_model = my_vgg16()\n",
        "\n",
        "#이 층들의 활성화를 이용합시다\n",
        "layer_names = [\n",
        "    'conv1_2', \n",
        "    'conv2_2',\n",
        "    'conv3_3',   \n",
        "    'conv4_3',   \n",
        "    'conv5_3',   \n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "down_stack.trainable = False\n",
        "\n",
        "# inputs = tf.keras.layers.Input(shape=[224, 224, 3])\n",
        "# x = inputs\n",
        "# # 모델을 통해 다운샘플링합시다\n",
        "# skips = down_stack(x)\n",
        "\n",
        "# # s1 = Conv2D(filters=1, kernel_size=1, name='stage1')(x1)\n",
        "# # s2 = Conv2D(filters=1, kernel_size=1, name='stage2')(x2)\n",
        "# # s3 = Conv2D(filters=1, kernel_size=1, name='stage3')(x3)\n",
        "# # s4 = Conv2D(filters=1, kernel_size=1, name='stage4')(x4)\n",
        "# # s5 = Conv2D(filters=1, kernel_size=1, name='stage5')(x5)\n",
        "\n",
        "conv1_2 = down_stack.get_layer('conv1_2').output\n",
        "conv2_2 = down_stack.get_layer('conv2_2').output\n",
        "conv3_3 = down_stack.get_layer('conv3_3').output\n",
        "conv4_3 = down_stack.get_layer('conv4_3').output\n",
        "conv5_3 = down_stack.get_layer('conv5_3').output\n",
        "\n",
        "\n",
        "s1 = Conv2D(filters=1, kernel_size=1, name='stage1')(conv1_2)\n",
        "s2 = Conv2D(filters=1, kernel_size=1, name='stage2')(conv2_2)\n",
        "s3 = Conv2D(filters=1, kernel_size=1, name='stage3')(conv3_3)\n",
        "s4 = Conv2D(filters=1, kernel_size=1, name='stage4')(conv4_3)\n",
        "s5 = Conv2D(filters=1, kernel_size=1, name='stage5')(conv5_3)\n",
        "\n",
        "y = UpSampling2D((2,2))(s5)\n",
        "y = UpSampling2D((2,2))(y)\n",
        "y = UpSampling2D((2,2))(y)\n",
        "y5 = UpSampling2D((2,2))(y)\n",
        "\n",
        "y = UpSampling2D((2,2))(s4)\n",
        "y = UpSampling2D((2,2))(y)\n",
        "y4 = UpSampling2D((2,2))(y)\n",
        "\n",
        "y = UpSampling2D((2,2))(s3)\n",
        "y3 = UpSampling2D((2,2))(y)\n",
        "\n",
        "y2 = UpSampling2D((2,2))(s2)\n",
        "\n",
        "y1 = s1\n",
        "\n",
        "concat = Concatenate()\n",
        "m = concat([y5, y4])\n",
        "m = concat([m, y3])\n",
        "m = concat([m, y2])\n",
        "m = concat([m, y1])\n",
        "m = Conv2D(filters=2, kernel_size=1, activation='sigmoid')(m)\n",
        "\n",
        "model = tf.keras.Model(inputs=down_stack.input, outputs=m)\n",
        "\n",
        "for layer in model.layers[:6]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9), loss=text_binary_crossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SrwrclPe74A"
      },
      "source": [
        "#model = textFCN_block()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwUiV8GrDtwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "b5e8be66-640e-4cf1-8d6a-585c2ade971e"
      },
      "source": [
        "model.load_weights(\"drive/MyDrive/weights/text_weights.h5\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-b7c8a10aa816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/weights/text_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2324\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2325\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    711\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    712\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m   \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3802\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    899\u001b[0m             (\"Cannot assign to variable%s due to variable shape %s and value \"\n\u001b[1;32m    900\u001b[0m              \"shape %s are incompatible\") %\n\u001b[0;32m--> 901\u001b[0;31m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[0m\u001b[1;32m    902\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    903\u001b[0m           self.handle, value_tensor, name=name)\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot assign to variable conv1_1/kernel:0 due to variable shape (3, 3, 3, 64) and value shape (3, 3, 64, 3) are incompatible"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExMLMW5WGSEj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}